{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to the Gaussian process regression \n",
    "## Solusion to the Practice ploblem\n",
    "\n",
    "\n",
    "Course\n",
    "- SURF 2016\n",
    "\n",
    "Lecturer :\n",
    "- Georgios Karagiannis, Department of Mathematics, Purdue\n",
    "\n",
    "July 8, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Objective :\n",
    "\n",
    "- We wish to build a Gaussian Process regression --a probabilistic surrogate model-- in order to be able to emulate the output of the Piston Simulator, with respect to specified inputs.\n",
    "\n",
    "Related material:\n",
    "\n",
    "    Readings :\n",
    "    \n",
    "    - Rasmussen, Carl Edward. \"Gaussian processes in machine learning.\" In Advanced lectures on machine learning, pp. 63-71. Springer Berlin Heidelberg, 2004. \t\n",
    "        - see http://www.GaussianProcess.org/gpml\n",
    "        - Chapters: 2, 4, 5.1, & 5.4.2\n",
    "\n",
    "    - Slides provided\n",
    "    \n",
    "    Software :\n",
    "    \n",
    "    - R-cran (https://cran.r-project.org/)\n",
    "    - R packages \n",
    "        - DiceKrigin (https://cran.r-project.org/web/packages/DiceKriging/index.html)\n",
    "        - lhs (https://cran.r-project.org/web/packages/lhs/index.html)\n",
    "    - Roustant, Olivier, David Ginsbourger, and Yves Deville. \"DiceKriging, DiceOptim: Two R packages for the analysis of computer experiments by kriging-based metamodeling and optimization.\" (2012).\n",
    "        - Plus dependences ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Catalytic Conversion of Nitrate to Nitrogen model\n",
    "\n",
    "## Example: Catalytic Conversion of Nitrate to Nitrogen\n",
    "\n",
    "This is Example 3.1 of [Tsilifis, Panagiotis, Ilias Bilionis, Ioannis Katsounaros, and Nicholas Zabaras. \"Variational Reformulation of Bayesian Inverse Problems.\" arXiv preprint arXiv:1410.5522 (2014)].\n",
    "\n",
    "Consider the catalytic\n",
    "conversion of nitrate ($\\mbox{NO}_3^-$) to nitrogen ($\\mbox{N}_2$) and other\n",
    "by-products by electrochemical means.\n",
    "The mechanism that is followed is complex and not well understood.\n",
    "The experiment of \\cite{katsounaros} confirmed the\n",
    "production of nitrogen ($\\mbox{N}_2$), ammonia\n",
    "($\\mbox{NH}_3$), and nitrous oxide ($\\mbox{N}_2\\mbox{O}$) as final products\n",
    "of the reaction, as well as the intermediate production of nitrite ($\\mbox{NO}_2^-$).\n",
    "The time is measured in minutes and the conentrations are measured in $\\mbox{mmol}\\cdot\\mbox{L}^{-1}$.\n",
    "Let's load the data into this notebook using the [Pandas](http://pandas.pydata.org) Python module:\n",
    "\n",
    "\n",
    "This inconsistency suggests the existence of an intermediate unobserved reaction product X.\n",
    "[Katsounaros, Ioannis, Maria Dortsiou, Christos Polatides, Simon Preston, Theodore Kypraios, and Georgios Kyriacou. \"Reaction pathways in the electrochemical reduction of nitrate on tin.\" Electrochimica Acta 71 (2012): 270-276.] suggested that the following reaction path shown in the following figure.\n",
    "\n",
    "\n",
    "![](./plots/scheme.png \"Reaction Scheme\")\n",
    "\n",
    "The dynamical system associated with the reaction is:\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\frac{d \\left[\\mbox{NO}_3^-\\right]}{dt} &= -k_1\\left[\\mbox{NO}_3^-\\right], \\\\\n",
    "\\frac{d\\left[\\mbox{NO}_2^-\\right]}{dt} &= k_1\\left[\\mbox{NO}_3^-\\right] - (k_2 + k_4 +\n",
    "k_5)[\\mbox{NO}_2^-], \\\\\n",
    "\\frac{d \\left[\\mbox{X}\\right]}{dt} &= k_2 \\left[\\mbox{NO}_2^-\\right] - k_3 [X],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2\\right]}{dt} &= k_3 \\left[\\mbox{X}\\right], \\\\\n",
    "\\frac{d \\left[\\mbox{NH}_3\\right]}{dt} &= k_4 \\left[\\mbox{NO}_2^-\\right],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2O\\right]}{dt} &= k_5 \\left[\\mbox{NO}_2^-\\right],\n",
    "\\end{array}\n",
    "$$\n",
    "where $[\\cdot]$ denotes the concentration of a quantity, and\n",
    "$k_i > 0$, $i=1,...5$ are the *kinetic rate constants*.\n",
    "\n",
    "### Computational Model\n",
    "\n",
    "We will develop a generic computational model for the solution of dynamical systems and we will use it to study the catalysis problem. The code relies on the [Fourth-order Runge-Kutta method](https://en.wikipedia.org/wiki/Runge–Kutta_methods) and is a modified copy of [http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py](http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py) developed by Jonathan Senning. The code solves:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{\\mathbf{y}} &=& f(\\mathbf{y}, t),\\\\\n",
    "\\mathbf{y}(0) &=& \\mathbf{y}_0.\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The input values are:\n",
    "\n",
    "| Variable | Value |\n",
    "|---------|------------------|\n",
    "| $\\xi_1$ |$1.35\\pm 0.05$ |\n",
    "| $\\xi_2$ |$1.65\\pm 0.08$   |\n",
    "| $\\xi_3$ |$1.34\\pm 0.11$ |\n",
    "| $\\xi_4$ |$-0.16\\pm 0.16$ |\n",
    "| $\\xi_5$ |$-3.84\\pm 0.20$ |\n",
    "\n",
    "\n",
    "The output values of the simulator are the concentrations (in $\\mbox{mmol}\\cdot\\mbox{L}^{-1}$) of $\\mbox{NO}_3^-$, $\\mbox{NO}_2^-$, X ( unobserved reaction product),  $\\mbox{N}_2$, $\\mbox{NH}_3$, $\\mbox{N}_2\\mbox{O}$, and $\\mbox{NO}_2^-$.\n",
    "\n",
    "The R code in './catalytic.R' provides a simulator that returns only one output value (selected by the user), given the values of the 5 inputs.\n",
    "\n",
    "\n",
    "Tsilifis, Panagiotis, Ilias Bilionis, Ioannis Katsounaros, and Nicholas Zabaras. \"Variational Reformulation of Bayesian Inverse Problems.\" arXiv preprint arXiv:1410.5522 (2014)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Software preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/export/users/gkaragia/R/x86_64-redhat-linux-gnu-library/3.3’\n",
      "(as ‘lib’ is unspecified)\n",
      "Warning message:\n",
      "In install.packages(\"DiceKriging\", repos = \"http://cran.us.r-project.org\"): installation of package ‘DiceKriging’ had non-zero exit statusInstalling package into ‘/export/users/gkaragia/R/x86_64-redhat-linux-gnu-library/3.3’\n",
      "(as ‘lib’ is unspecified)\n",
      "Warning message:\n",
      "In install.packages(\"lhs\", repos = \"http://cran.us.r-project.org\"): installation of package ‘lhs’ had non-zero exit status"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD THE R PACKAGES REQUIRED\n",
    "install.packages('DiceKriging', repos = \"http://cran.us.r-project.org\")\n",
    "install.packages('lhs', repos = \"http://cran.us.r-project.org\")\n",
    "# install.packages('tcltk', repos = \"http://cran.us.r-project.org\")\n",
    "# install.packages('aplpack', repos = \"http://cran.us.r-project.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD THE R PACKAGES REQUIRED\n",
    "library('lhs')\n",
    "library('DiceKriging')\n",
    "# library('tcltk')\n",
    "# library('aplpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# THIS IS THE SIMULATOR AND THE MIN AND MAX OF THE INPUTS\n",
    "\n",
    "source(\"./catalytic.R\") # function: output_1d <- simulator(input_5d, jout=4)\n",
    "input_min <- c(1.30,  1.57,  1.23, -0.32, -4.04)\n",
    "input_max <- c(1.40,  1.73,  1.45,  0.00, -3.64)\n",
    "input_d <- length(input_min)\n",
    "\n",
    "# par(mfrow=c(2,3))\n",
    "# for (i in 1:6) {\n",
    "#     n_data <- 500 ;\n",
    "#     n_dim <- input_d\n",
    "#     X_data <- t(input_min + (input_max-input_min)*t(matrix(runif(n_data*n_dim),n_data, n_dim))) ;\n",
    "#     myfun <-function(xi){ return(simulator(xi,i))}\n",
    "#     Y_data <- apply(X_data, 1, myfun) ;\n",
    "#     hist(Y_data)\n",
    "# }\n",
    "\n",
    "myfun <- function(xx) {return(simulator(xx, jout=4)) }\n",
    "\n",
    "# # PLOT THE REAL FUNCTION TO SEE HOW IT LOOKS LIKE\n",
    "\n",
    "# par(mfrow = c(3,3))\n",
    "# for (i in 1:input_d) {\n",
    "#     for ( j in 1:input_d ) \n",
    "#         if(i>j) {\n",
    "#         n.grid <- 100 ;\n",
    "#         x1.grid <-seq(input_min[i],input_max[i],length.out=n.grid) ;\n",
    "#         x2.grid <-seq(input_min[j],input_max[j],length.out=n.grid) ;\n",
    "#         X.grid <- expand.grid( x1=x1.grid,  x2=x2.grid )\n",
    "#         myfun2d<-function(xx){ \n",
    "#                             zz<-0.5*(input_min+input_max) ; \n",
    "#                             zz[i]<-xx[1]; zz[j]<-xx[2]; \n",
    "#                             return(myfun(zz)) \n",
    "#                     }\n",
    "#         y.grid <- apply(X.grid,1,myfun2d)\n",
    "#     contour(x1.grid, x2.grid, matrix(y.grid, n.grid, n.grid), 10, \n",
    "#             main = \"Real function\", \n",
    "#             xlab = paste(\"x\", as.character(i)), \n",
    "#             ylab = paste(\"x\", as.character(j)),\n",
    "#             xlim = c(input_min[i],input_max[i]), \n",
    "#             ylim = c(input_min[j],input_max[j]))\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate a training data-set\n",
    "\n",
    "Generate a training data-set $D={(x_i,y_i);i=1,...,n}$  of size $n=20$ via a LHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Have a look to the functions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for km {DiceKriging}\"><tr><td>km {DiceKriging}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2> Fit and/or create kriging models </h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>km</code> is used to fit kriging models when parameters are unknown, or to create <code>km</code> objects otherwise. In both cases, the result is a <code>km</code> object. If parameters are unknown, they are estimated by Maximum Likelihood. As a beta version, Penalized Maximum Likelihood Estimation is also possible if some penalty is given, or Leave-One-Out for noise-free observations.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "km(formula=~1, design, response, covtype=\"matern5_2\",\n",
       "   coef.trend = NULL, coef.cov = NULL, coef.var = NULL,\n",
       "   nugget = NULL, nugget.estim=FALSE, noise.var=NULL, estim.method=\"MLE\",\n",
       "   penalty = NULL, optim.method = \"BFGS\", lower = NULL, upper = NULL, \n",
       "   parinit = NULL, multistart = 1, control = NULL, gr = TRUE, \n",
       "   iso=FALSE, scaling=FALSE, knots=NULL, kernel=NULL)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula</code></td>\n",
       "<td>\n",
       "<p> an optional object of class &quot;formula&quot; specifying the linear trend of the kriging model (see <code>lm</code>). This formula should concern only the input variables, and not the output (response). If there is any, it is automatically dropped. In particular, no response transformation is available yet. The default is <code>~1</code>, which defines a constant trend.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>design</code></td>\n",
       "<td>\n",
       "<p> a data frame representing the design of experiments. The ith row contains the values of the d input variables corresponding to the ith evaluation</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>response</code></td>\n",
       "<td>\n",
       "<p> a vector (or 1-column matrix or data frame) containing the values of the 1-dimensional output given by the objective function at the <code>design</code> points. </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>covtype</code></td>\n",
       "<td>\n",
       "<p> an optional character string specifying the covariance structure to be used, to be chosen between <code>\"gauss\"</code>, <code>\"matern5_2\"</code>, <code>\"matern3_2\"</code>, <code>\"exp\"</code> or <code>\"powexp\"</code>. See a full description of available covariance kernels in <code>covTensorProduct-class</code>. Default is <code>\"matern5_2\"</code>. See also the argument <code>kernel</code> that allows the user to build its own covariance structure.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>coef.trend,</code></td>\n",
       "<td>\n",
       "<p> (see below)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>coef.cov,</code></td>\n",
       "<td>\n",
       "<p> (see below)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>coef.var</code></td>\n",
       "<td>\n",
       "<p> optional vectors containing the values for the trend, covariance and variance parameters. For estimation, 4 cases are implemented: 1. (All unknown) If all are missing, all are estimated. 2. (All known) If all are provided, no estimation is performed; 3. (Known trend) If <code>coef.trend</code> is provided but at least one of <code>coef.cov</code> or <code>coef.var</code> is missing, then BOTH <code>coef.cov</code> and <code>coef.var</code> are estimated; 4. (Unknown trend) If <code>coef.cov</code> and <code>coef.var</code> are provided but <code>coef.trend</code> is missing, then <code>coef.trend</code> is estimated (GLS formula).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nugget</code></td>\n",
       "<td>\n",
       "<p> an optional variance value standing for the homogeneous nugget effect.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nugget.estim</code></td>\n",
       "<td>\n",
       "<p> an optional boolean indicating whether the nugget effect should be estimated. Note that this option does not concern the case of heterogeneous noisy observations (see <code>noise.var</code> below). If <code>nugget</code> is given, it is used as an initial value. Default is <code>FALSE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>noise.var</code></td>\n",
       "<td>\n",
       "<p> for noisy observations : an optional vector containing the noise variance at each observation. This is useful for stochastic simulators. Default is <code>NULL</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>estim.method</code></td>\n",
       "<td>\n",
       "<p>  a character string specifying the method by which unknown parameters are estimated. Default is <code>\"MLE\"</code> (Maximum Likelihood). At this stage, a beta version of leave-One-Out estimation (<code>estim.method=\"LOO\"</code>) is also implemented for noise-free observations.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>penalty</code></td>\n",
       "<td>\n",
       "<p> (beta version) an optional list suitable for Penalized Maximum Likelihood Estimation. The list must contain the item <code>fun</code> indicating the penalty function, and the item <code>value</code> equal to the value of the penalty parameter. At this stage the only available <code>fun</code> is <code>\"SCAD\"</code>, and <code>covtype</code> must be <code>\"gauss\"</code>. Default is <code>NULL</code>, corresponding to (un-penalized) Maximum Likelihood Estimation.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>optim.method</code></td>\n",
       "<td>\n",
       "<p> an optional character string indicating which optimization method is chosen for the likelihood maximization. <code>\"BFGS\"</code> is the <code>optim</code> quasi-Newton procedure of package <code>stats</code>, with the method &quot;L-BFGS-B&quot;. <code>\"gen\"</code> is the <code>genoud</code> genetic algorithm (using derivatives) from package <code>rgenoud</code> (&gt;= 5.3.3). </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lower, </code></td>\n",
       "<td>\n",
       "<p> (see below) </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>upper</code></td>\n",
       "<td>\n",
       "<p> optional vectors containing the bounds of the correlation parameters for optimization. The default values are given by <code>covParametersBounds</code>. </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>parinit</code></td>\n",
       "<td>\n",
       "<p> an optional vector containing the initial values for the variables to be optimized over. If no vector is given, an initial point is generated as follows. For method <code>\"gen\"</code>, the initial point is generated uniformly inside the hyper-rectangle domain defined by <code>lower</code> and <code>upper</code>. For method <code>\"BFGS\"</code>, some points (see <code>control</code> below) are generated uniformly in the domain. Then the best point with respect to the likelihood (or penalized likelihood, see <code>penalty</code>) criterion is chosen. </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>multistart</code></td>\n",
       "<td>\n",
       "<p> an optional integer indicating the number of initial points from which running the BFGS optimizer. These points will be selected as the best <code>multistart</code> one(s) among those evaluated (see above <code>parinit</code>). The multiple optimizations will be performed in parallel provided that a parallel backend is registered (see package <code>foreach</code>).</p>\n",
       "</td></tr> \n",
       "<tr valign=\"top\"><td><code>control</code></td>\n",
       "<td>\n",
       "<p> an optional list of control parameters for optimization. See details below.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>gr</code></td>\n",
       "<td>\n",
       "<p> an optional boolean indicating whether the analytical gradient should be used. Default is <code>TRUE</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>iso</code></td>\n",
       "<td>\n",
       "<p> an optional boolean that can be used to force a tensor-product covariance structure (see <code>covTensorProduct-class</code>) to have a range parameter common to all dimensions. Default is <code>FALSE</code>. Not used (at this stage) for the power-exponential type.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>scaling</code></td>\n",
       "<td>\n",
       "<p> an optional boolean indicating whether a scaling on the covariance structure should be used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>knots</code></td>\n",
       "<td>\n",
       "<p> an optional list of knots for scaling. The j-th element is a vector containing the knots for dimension j. If <code>scaling=TRUE</code> and knots are not specified, than knots are fixed to 0 and 1 in each dimension (which corresponds to affine scaling for the domain [0,1]^d).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>kernel</code></td>\n",
       "<td>\n",
       "<p> an optional function containing a new covariance structure. At this stage, the parameters must be provided as well, and are not estimated. See an example below.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The optimisers are tunable by the user by the argument <code>control</code>. \n",
       "Most of the control parameters proposed by <code>BFGS</code> and <code>genoud</code> can be passed to <code>control</code> except the ones that must be forced [for the purpose of optimization setting], as indicated in the table below. See <code>optim</code> and  <code>genoud</code> to get more details about them.\n",
       "</p>\n",
       "\n",
       "<table summary=\"Rd table\">\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "BFGS </td><td style=\"text-align: left;\"> <code>trace</code>, <code>parscale</code>, <code>ndeps</code>, <code>maxit</code>, <code>abstol</code>, <code>reltol</code>, <code>REPORT</code>, <code>lnm</code>, <code>factr</code>, <code>pgtol</code> </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "genoud </td><td style=\"text-align: left;\"> all parameters EXCEPT: <code>fn, nvars, max, starting.values, Domains, gr, gradient.check, boundary.enforcement, hessian</code> and <code>optim.method</code>. </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\"> \n",
       "</td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "<p>Notice that the right places to specify the optional starting values and boundaries are in <code>parinit</code> and <code>lower, upper</code>, as explained above. Some additional possibilities and initial values are indicated in the table below:\n",
       "</p>\n",
       "\n",
       "<table summary=\"Rd table\">\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "<code>trace</code> </td><td style=\"text-align: left;\"> Turn it to <code>FALSE</code> to avoid printing during optimization progress.</td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "\n",
       "<code>pop.size</code> </td><td style=\"text-align: left;\"> For method <code>\"BFGS\"</code>, it is the number of candidate initial points generated before optimization starts (see <code>parinit</code> above). Default is 20. For method <code>\"gen\"</code>, <code>\"pop.size\"</code> is the population size, set by default at min(20, 4+3*log(nb of variables) </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "<code>max.generations</code> </td><td style=\"text-align: left;\"> Default is 5 </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "<code>wait.generations</code> </td><td style=\"text-align: left;\"> Default is 2 </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "<code>BFGSburnin</code> </td><td style=\"text-align: left;\"> Default is 0 </td>\n",
       "</tr>\n",
       "<tr>\n",
       " <td style=\"text-align: left;\">\n",
       "</td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>An object of class <code>km</code> (see <code>km-class</code>).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p> O. Roustant, D. Ginsbourger, Ecole des Mines de St-Etienne. </p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       " \n",
       "<p>N.A.C. Cressie (1993), <em>Statistics for spatial data</em>, Wiley series in probability and mathematical statistics.\n",
       "</p>\n",
       "<p>D. Ginsbourger (2009), <em>Multiples metamodeles pour l'approximation et l'optimisation\n",
       "de fonctions numeriques multivariables</em>, Ph.D. thesis, Ecole Nationale Superieure des\n",
       "Mines de Saint-Etienne, 2009.\n",
       "</p>\n",
       "<p>D. Ginsbourger, D. Dupuy, A. Badea, O. Roustant, and L. Carraro (2009), A note on the choice and the estimation of kriging models for the analysis of deterministic computer experiments, <em>Applied Stochastic Models for Business and Industry</em>, <b>25</b> no. 2, 115-131.\n",
       "</p>\n",
       "<p>A.G. Journel and M.E. Rossi (1989), When do we need a trend model in kriging ?, <em>Mathematical Geology</em>, <b>21</b> no. 7, 715-739.\n",
       "</p>\n",
       "<p>D.G. Krige (1951), A statistical approach to some basic mine valuation problems on the witwatersrand, <em>J. of the Chem., Metal. and Mining Soc. of South Africa</em>, <b>52</b> no. 6, 119-139.\n",
       "</p>\n",
       "<p>R. Li and A. Sudjianto (2005), Analysis of Computer Experiments Using Penalized Likelihood in Gaussian Kriging Models, <em>Technometrics</em>, <b>47</b> no. 2, 111-120.\n",
       "</p>\n",
       "<p>K.V. Mardia and R.J. Marshall (1984), Maximum likelihood estimation of models for residual covariance in spatial regression, <em>Biometrika</em>, <b>71</b>, 135-146.\n",
       "</p>\n",
       "<p>J.D. Martin and T.W. Simpson (2005), Use of kriging models to approximate deterministic computer models, <em>AIAA Journal</em>, <b>43</b> no. 4, 853-863.\n",
       "</p>\n",
       "<p>G. Matheron (1969), Le krigeage universel, <em>Les Cahiers du Centre de Morphologie Mathematique de Fontainebleau</em>, <b>1</b>.\n",
       "</p>\n",
       "<p>W.R. Jr. Mebane and J.S. Sekhon, in press (2009), Genetic optimization using derivatives: The rgenoud package for R, <em>Journal of Statistical Software</em>.\n",
       "</p>\n",
       "<p>J.-S. Park and J. Baek (2001), Efficient computation of maximum likelihood estimators in a spatial linear model with power exponential covariogram, <em>Computer Geosciences</em>, <b>27</b> no. 1, 1-7.\n",
       "</p>\n",
       "<p>C.E. Rasmussen and C.K.I. Williams (2006), <em>Gaussian Processes for Machine Learning</em>, the MIT Press, <a href=\"http://www.GaussianProcess.org/gpml\">http://www.GaussianProcess.org/gpml</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       " <p><code>kmData</code> for another interface with the data,\n",
       "<code>show,km-method</code>,\n",
       "<code>predict,km-method</code>,\n",
       "<code>plot,km-method</code>.\n",
       "Some programming details and initialization choices can be found in <code>kmEstimate</code>, <code>kmNoNugget.init</code>,\n",
       "<code>km1Nugget.init</code> and <code>kmNuggets.init</code> </p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "\n",
       "# ----------------------------------\n",
       "# A 2D example - Branin-Hoo function\n",
       "# ----------------------------------\n",
       "\n",
       "# a 16-points factorial design, and the corresponding response\n",
       "d &lt;- 2; n &lt;- 16\n",
       "design.fact &lt;- expand.grid(x1=seq(0,1,length=4), x2=seq(0,1,length=4))\n",
       "y &lt;- apply(design.fact, 1, branin) \n",
       "\n",
       "# kriging model 1 : matern5_2 covariance structure, no trend, no nugget effect\n",
       "m1 &lt;- km(design=design.fact, response=y)\n",
       "\n",
       "# kriging model 2 : matern5_2 covariance structure, \n",
       "#                   linear trend + interactions, no nugget effect\n",
       "m2 &lt;- km(~.^2, design=design.fact, response=y)\n",
       "\n",
       "# graphics \n",
       "n.grid &lt;- 50\n",
       "x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)\n",
       "design.grid &lt;- expand.grid(x1=x.grid, x2=y.grid)\n",
       "response.grid &lt;- apply(design.grid, 1, branin)\n",
       "predicted.values.model1 &lt;- predict(m1, design.grid, \"UK\")$mean\n",
       "predicted.values.model2 &lt;- predict(m2, design.grid, \"UK\")$mean\n",
       "par(mfrow=c(3,1))\n",
       "contour(x.grid, y.grid, matrix(response.grid, n.grid, n.grid), 50, main=\"Branin\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "contour(x.grid, y.grid, matrix(predicted.values.model1, n.grid, n.grid), 50, \n",
       "        main=\"Ordinary Kriging\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "contour(x.grid, y.grid, matrix(predicted.values.model2, n.grid, n.grid), 50, \n",
       "        main=\"Universal Kriging\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "par(mfrow=c(1,1))\n",
       "\n",
       "\n",
       "# (same example) how to use the multistart argument\n",
       "# -------------------------------------------------\n",
       "require(foreach)\n",
       "\n",
       "# below an example for a computer with 2 cores, but also work with 1 core\n",
       "\n",
       "nCores &lt;- 2\n",
       "require(doParallel)\n",
       "cl &lt;-  makeCluster(nCores) \n",
       "registerDoParallel(cl)\n",
       "\n",
       "# kriging model 1, with 4 starting points\n",
       "m1_4 &lt;- km(design=design.fact, response=y, multistart=4)\n",
       "\n",
       "stopCluster(cl)\n",
       "\n",
       "# -------------------------------\n",
       "# A 1D example with penalized MLE\n",
       "# -------------------------------\n",
       "\n",
       "# from Fang K.-T., Li R. and Sudjianto A. (2006), \"Design and Modeling for \n",
       "# Computer Experiments\", Chapman &amp; Hall, pages 145-152\n",
       "\n",
       "n &lt;- 6; d &lt;- 1\n",
       "x &lt;- seq(from=0, to=10, length=n)\n",
       "y &lt;- sin(x)\n",
       "t &lt;- seq(0,10, length=100)\n",
       "\n",
       "# one should add a small nugget effect, to avoid numerical problems\n",
       "epsilon &lt;- 1e-3\n",
       "model &lt;- km(formula&lt;- ~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"gauss\", penalty=list(fun=\"SCAD\", value=3), nugget=epsilon)\n",
       "\n",
       "p &lt;- predict(model, data.frame(x=t), \"UK\")\n",
       "\n",
       "plot(t, p$mean, type=\"l\", xlab=\"x\", ylab=\"y\", \n",
       "                     main=\"Prediction via Penalized Kriging\")\n",
       "points(x, y, col=\"red\", pch=19)\n",
       "lines(t, sin(t), lty=2, col=\"blue\")\n",
       "legend(0, -0.5, legend=c(\"Sine Curve\", \"Sample\", \"Fitted Curve\"), \n",
       "       pch=c(-1,19,-1), lty=c(2,-1,1), col=c(\"blue\",\"red\",\"black\"))\n",
       "\n",
       "\n",
       "# ------------------------------------------------------------------------\n",
       "# A 1D example with known trend and known or unknown covariance parameters\n",
       "# ------------------------------------------------------------------------\n",
       "\n",
       "x &lt;- c(0, 0.4, 0.6, 0.8, 1);\n",
       "y &lt;- c(-0.3, 0, -0.8, 0.5, 0.9)\n",
       "\n",
       "theta &lt;- 0.01; sigma &lt;- 3; trend &lt;- c(-1,2)\n",
       "\n",
       "model &lt;- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"matern5_2\", coef.trend=trend, coef.cov=theta, \n",
       "            coef.var=sigma^2)\n",
       "\n",
       "# below: if you want to specify trend only, and estimate both theta and sigma:\n",
       "# model &lt;- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "#             covtype=\"matern5_2\", coef.trend=trend, lower=0.2)\n",
       "# Remark: a lower bound or penalty function is useful here,\n",
       "#         due to the very small number of design points...\n",
       "\n",
       "# kriging with gaussian covariance C(x,y)=sigma^2 * exp(-[(x-y)/theta]^2), \n",
       "#         and linear trend t(x) = -1 + 2x\n",
       "\n",
       "t &lt;- seq(from=0, to=1, by=0.005)\n",
       "p &lt;- predict(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "# beware that type = \"SK\" for known parameters (default is \"UK\")\n",
       "\n",
       "plot(t, p$mean, type=\"l\", ylim=c(-7,7), xlab=\"x\", ylab=\"y\")\n",
       "lines(t, p$lower95, col=\"black\", lty=2)\n",
       "lines(t, p$upper95, col=\"black\", lty=2)\n",
       "points(x, y, col=\"red\", pch=19)\n",
       "abline(h=0)\n",
       "\n",
       "\n",
       "# --------------------------------------------------------------\n",
       "# Kriging with noisy observations (heterogeneous noise variance)\n",
       "# --------------------------------------------------------------\n",
       "\n",
       "fundet &lt;- function(x){\n",
       "return((sin(10*x)/(1+x)+2*cos(5*x)*x^3+0.841)/1.6)\n",
       "}\n",
       "\n",
       "level &lt;- 0.5; epsilon &lt;- 0.1\n",
       "theta &lt;- 1/sqrt(30); p &lt;- 2; n &lt;- 10\n",
       "x &lt;- seq(0,1, length=n)\n",
       "\n",
       "# Heteregeneous noise variances: number of Monte Carlo evaluation among \n",
       "#                                a total budget of 1000 stochastic simulations\n",
       "MC_numbers &lt;- c(10,50,50,290,25,75,300,10,40,150)\n",
       "noise.var &lt;- 3/MC_numbers\n",
       "\n",
       "# Making noisy observations from 'fundet' function (defined above)\n",
       "y &lt;- fundet(x) + noise.var*rnorm(length(x))\n",
       "\n",
       "# kriging model definition (no estimation here)\n",
       "model &lt;- km(y~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"gauss\", coef.trend=0, coef.cov=theta, coef.var=1, \n",
       "            noise.var=noise.var)\n",
       "\n",
       "# prediction\n",
       "t &lt;- seq(0, 1, by=0.01)\n",
       "p &lt;- predict.km(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "lower &lt;- p$lower95; upper &lt;- p$upper95\n",
       "\n",
       "# graphics\n",
       "par(mfrow=c(1,1))\n",
       "plot(t, p$mean, type=\"l\", ylim=c(1.1*min(c(lower,y)) , 1.1*max(c(upper,y))), \n",
       "                xlab=\"x\", ylab=\"y\",col=\"blue\", lwd=1.5)\n",
       "polygon(c(t,rev(t)), c(lower, rev(upper)), col=gray(0.9), border = gray(0.9))\n",
       "lines(t, p$mean, type=\"l\", ylim=c(min(lower) ,max(upper)), xlab=\"x\", ylab=\"y\",\n",
       "                 col=\"blue\", lwd=1)\n",
       "lines(t, lower, col=\"blue\", lty=4, lwd=1.7)\n",
       "lines(t, upper, col=\"blue\", lty=4, lwd=1.7)\n",
       "lines(t, fundet(t), col=\"black\", lwd=2)\n",
       "points(x, y, pch=8,col=\"blue\")\n",
       "text(x, y, labels=MC_numbers, pos=3)\n",
       "\n",
       "\n",
       "# -----------------------------\n",
       "# Checking parameter estimation \n",
       "# -----------------------------\n",
       "\n",
       "d &lt;- 3       \t# problem dimension\n",
       "n &lt;- 40\t\t\t# size of the experimental design\n",
       "design &lt;- matrix(runif(n*d), n, d)\n",
       "\n",
       "covtype &lt;- \"matern5_2\"\t\t\n",
       "theta &lt;- c(0.3, 0.5, 1)\t\t# the parameters to be found by estimation\n",
       "sigma &lt;- 2\n",
       "nugget &lt;- NULL  # choose a numeric value if you want to estimate nugget \n",
       "nugget.estim &lt;- FALSE # choose TRUE if you want to estimate it\n",
       "\n",
       "n.simu &lt;- 30\t\t# number of simulations\n",
       "sigma2.estimate &lt;- nugget.estimate &lt;- mu.estimate &lt;- matrix(0, n.simu, 1)\n",
       "coef.estimate &lt;- matrix(0, n.simu, length(theta))\n",
       "\n",
       "model &lt;- km(~1, design=data.frame(design), response=rep(0,n), covtype=covtype, \n",
       "            coef.trend=0, coef.cov=theta, coef.var=sigma^2, nugget=nugget)\n",
       "y &lt;- simulate(model, nsim=n.simu)\n",
       "\n",
       "for (i in 1:n.simu) {\n",
       "\t# parameter estimation: tune the optimizer by changing optim.method, control\n",
       "\tmodel.estimate &lt;- km(~1, design=data.frame(design), response=data.frame(y=y[i,]), \n",
       "\tcovtype=covtype, optim.method=\"BFGS\", control=list(pop.size=50, trace=FALSE), \n",
       "        nugget.estim=nugget.estim) \n",
       "\t\n",
       "\t# store results\n",
       "\tcoef.estimate[i,] &lt;- covparam2vect(model.estimate@covariance)\n",
       "\tsigma2.estimate[i] &lt;- model.estimate@covariance@sd2\n",
       "\tmu.estimate[i] &lt;- model.estimate@trend.coef\n",
       "\tif (nugget.estim) nugget.estimate[i] &lt;- model.estimate@covariance@nugget\n",
       "}\n",
       "\n",
       "# comparison true values / estimation\n",
       "cat(\"\\nResults with \", n, \"design points, \n",
       "    obtained with \", n.simu, \"simulations\\n\\n\",\n",
       "    \"Median of covar. coef. estimates: \", apply(coef.estimate, 2, median), \"\\n\",\n",
       "    \"Median of trend  coef. estimates: \", median(mu.estimate), \"\\n\", \n",
       "    \"Mean of the var. coef. estimates: \", mean(sigma2.estimate))\n",
       "if (nugget.estim) cat(\"\\nMean of the nugget effect estimates: \", \n",
       "                      mean(nugget.estimate))\n",
       "\n",
       "# one figure for this specific example - to be adapted\n",
       "split.screen(c(2,1))        # split display into two screens\n",
       "split.screen(c(1,2), screen = 2) # now split the bottom half into 3\n",
       "\n",
       "screen(1)\n",
       "boxplot(coef.estimate[,1], coef.estimate[,2], coef.estimate[,3], \n",
       "        names=c(\"theta1\", \"theta2\", \"theta3\"))\n",
       "abline(h=theta, col=\"red\")\n",
       "fig.title &lt;- paste(\"Empirical law of the parameter estimates \n",
       "                    (n=\", n , \", n.simu=\", n.simu, \")\", sep=\"\")\n",
       "title(fig.title)\n",
       "\n",
       "screen(3)\n",
       "boxplot(mu.estimate, xlab=\"mu\")\n",
       "abline(h=0, col=\"red\")\n",
       "\n",
       "screen(4)\n",
       "boxplot(sigma2.estimate, xlab=\"sigma2\")\n",
       "abline(h=sigma^2, col=\"red\")\n",
       "\n",
       "close.screen(all = TRUE)  \n",
       "\n",
       "# ----------------------------------------------------------\n",
       "# Kriging with non-linear scaling on Xiong et al.'s function\n",
       "# ----------------------------------------------------------\n",
       "\n",
       "f11_xiong &lt;- function(x){ \n",
       "return( sin(30*(x - 0.9)^4)*cos(2*(x - 0.9)) + (x - 0.9)/2)\n",
       "}\n",
       "\n",
       "t &lt;- seq(0,1,,300)\n",
       "f &lt;- f11_xiong(t)\n",
       "\n",
       "plot(t,f,type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "\n",
       "doe &lt;- data.frame(x=seq(0,1,,20))\n",
       "resp &lt;- f11_xiong(doe)\n",
       "\n",
       "knots &lt;- list(  c(0,0.5,1) ) \n",
       "eta &lt;- list(c(15, 2, 0.5))\n",
       "m &lt;- km(design=doe, response=resp, scaling=TRUE, gr=TRUE, \n",
       "knots=knots, covtype=\"matern5_2\",  coef.var=1, coef.trend=0)\n",
       "\n",
       "p &lt;- predict(m, data.frame(x=t), \"UK\")\n",
       "\n",
       "plot(t, f, type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "\n",
       "lines(t, p$mean, col=\"blue\", lty=2, lwd=2)\n",
       "lines(t, p$mean + 2*p$sd, col=\"blue\")\n",
       "lines(t, p$mean - 2*p$sd,col=\"blue\")\n",
       "\n",
       "abline(v=knots[[1]], lty=2, col=\"green\")\n",
       "\n",
       "\n",
       "# -----------------------------------------------------\n",
       "# Kriging with a symmetric kernel: example with covUser\n",
       "# -----------------------------------------------------\n",
       "\n",
       "x &lt;- c(0, 0.15, 0.3, 0.4, 0.5)\n",
       "y &lt;- c(0.3, -0.2, 0, 0.5, 0.2)\n",
       "\n",
       "k &lt;- function(x,y) {\n",
       "  theta &lt;- 0.15\n",
       "  0.5*exp(-((x-y)/theta)^2) + 0.5*exp(-((1-x-y)/theta)^2)    \n",
       "}\n",
       "\n",
       "muser &lt;- km(design=data.frame(x=x), response=data.frame(y=y), \n",
       "            coef.trend=0, kernel=k)\n",
       "\n",
       "u &lt;- seq(from=0, to=1, by=0.01)\n",
       "puser &lt;- predict(muser, newdata=data.frame(x=u), type=\"SK\")\n",
       "\n",
       "set.seed(0)\n",
       "nsim &lt;- 5\n",
       "zuser &lt;- simulate(muser, nsim=nsim, newdata=data.frame(x=u), cond=TRUE, nugget.sim=1e-8)\n",
       "par(mfrow=c(1,1))\n",
       "matplot(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "polygon(c(u, rev(u)), c(puser$upper, rev(puser$lower)), col=\"lightgrey\", border=NA)\n",
       "lines(u, puser$mean, lwd=5, col=\"blue\", lty=\"dotted\")\n",
       "matlines(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "points(x, y, pch=19, cex=1.5)\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>DiceKriging</em> version 1.5.5 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{km}{ Fit and/or create kriging models }{km}\n",
       "\\keyword{models}{km}\n",
       "\\keyword{htest}{km}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{km} is used to fit kriging models when parameters are unknown, or to create \\code{km} objects otherwise. In both cases, the result is a \\code{km} object. If parameters are unknown, they are estimated by Maximum Likelihood. As a beta version, Penalized Maximum Likelihood Estimation is also possible if some penalty is given, or Leave-One-Out for noise-free observations.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "km(formula=~1, design, response, covtype=\"matern5_2\",\n",
       "   coef.trend = NULL, coef.cov = NULL, coef.var = NULL,\n",
       "   nugget = NULL, nugget.estim=FALSE, noise.var=NULL, estim.method=\"MLE\",\n",
       "   penalty = NULL, optim.method = \"BFGS\", lower = NULL, upper = NULL, \n",
       "   parinit = NULL, multistart = 1, control = NULL, gr = TRUE, \n",
       "   iso=FALSE, scaling=FALSE, knots=NULL, kernel=NULL)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula}]  an optional object of class \"formula\" specifying the linear trend of the kriging model (see \\code{\\LinkA{lm}{lm}}). This formula should concern only the input variables, and not the output (response). If there is any, it is automatically dropped. In particular, no response transformation is available yet. The default is \\code{\\textasciitilde{}1}, which defines a constant trend.\n",
       "\\item[\\code{design}]  a data frame representing the design of experiments. The ith row contains the values of the d input variables corresponding to the ith evaluation\n",
       "\\item[\\code{response}]  a vector (or 1-column matrix or data frame) containing the values of the 1-dimensional output given by the objective function at the \\code{design} points. \n",
       "\\item[\\code{covtype}]  an optional character string specifying the covariance structure to be used, to be chosen between \\code{\"gauss\"}, \\code{\"matern5\\_2\"}, \\code{\"matern3\\_2\"}, \\code{\"exp\"} or \\code{\"powexp\"}. See a full description of available covariance kernels in \\code{\\LinkA{covTensorProduct-class}{covTensorProduct.Rdash.class}}. Default is \\code{\"matern5\\_2\"}. See also the argument \\code{kernel} that allows the user to build its own covariance structure.\n",
       "\\item[\\code{coef.trend,}]  (see below)\n",
       "\\item[\\code{coef.cov,}]  (see below)\n",
       "\\item[\\code{coef.var}]  optional vectors containing the values for the trend, covariance and variance parameters. For estimation, 4 cases are implemented: 1. (All unknown) If all are missing, all are estimated. 2. (All known) If all are provided, no estimation is performed; 3. (Known trend) If \\code{coef.trend} is provided but at least one of \\code{coef.cov} or \\code{coef.var} is missing, then BOTH \\code{coef.cov} and \\code{coef.var} are estimated; 4. (Unknown trend) If \\code{coef.cov} and \\code{coef.var} are provided but \\code{coef.trend} is missing, then \\code{coef.trend} is estimated (GLS formula).\n",
       "\\item[\\code{nugget}]  an optional variance value standing for the homogeneous nugget effect.\n",
       "\\item[\\code{nugget.estim}]  an optional boolean indicating whether the nugget effect should be estimated. Note that this option does not concern the case of heterogeneous noisy observations (see \\code{noise.var} below). If \\code{nugget} is given, it is used as an initial value. Default is \\code{FALSE}.\n",
       "\\item[\\code{noise.var}]  for noisy observations : an optional vector containing the noise variance at each observation. This is useful for stochastic simulators. Default is \\code{NULL}.\n",
       "\\item[\\code{estim.method}]   a character string specifying the method by which unknown parameters are estimated. Default is \\code{\"MLE\"} (Maximum Likelihood). At this stage, a beta version of leave-One-Out estimation (\\code{estim.method=\"LOO\"}) is also implemented for noise-free observations.\n",
       "\\item[\\code{penalty}]  (beta version) an optional list suitable for Penalized Maximum Likelihood Estimation. The list must contain the item \\code{fun} indicating the penalty function, and the item \\code{value} equal to the value of the penalty parameter. At this stage the only available \\code{fun} is \\code{\"SCAD\"}, and \\code{covtype} must be \\code{\"gauss\"}. Default is \\code{NULL}, corresponding to (un-penalized) Maximum Likelihood Estimation.\n",
       "\\item[\\code{optim.method}]  an optional character string indicating which optimization method is chosen for the likelihood maximization. \\code{\"BFGS\"} is the \\code{optim} quasi-Newton procedure of package \\code{stats}, with the method \"L-BFGS-B\". \\code{\"gen\"} is the \\code{genoud} genetic algorithm (using derivatives) from package \\code{rgenoud} (>= 5.3.3). \n",
       "\\item[\\code{lower, }]  (see below) \n",
       "\\item[\\code{upper}]  optional vectors containing the bounds of the correlation parameters for optimization. The default values are given by \\code{\\LinkA{covParametersBounds}{covParametersBounds}}. \n",
       "\\item[\\code{parinit}]  an optional vector containing the initial values for the variables to be optimized over. If no vector is given, an initial point is generated as follows. For method \\code{\"gen\"}, the initial point is generated uniformly inside the hyper-rectangle domain defined by \\code{lower} and \\code{upper}. For method \\code{\"BFGS\"}, some points (see \\code{control} below) are generated uniformly in the domain. Then the best point with respect to the likelihood (or penalized likelihood, see \\code{penalty}) criterion is chosen. \n",
       "\\item[\\code{multistart}]  an optional integer indicating the number of initial points from which running the BFGS optimizer. These points will be selected as the best \\code{multistart} one(s) among those evaluated (see above \\code{parinit}). The multiple optimizations will be performed in parallel provided that a parallel backend is registered (see package \\code{foreach}).\n",
       "\\item[\\code{control}]  an optional list of control parameters for optimization. See details below.\n",
       "\\item[\\code{gr}]  an optional boolean indicating whether the analytical gradient should be used. Default is \\code{TRUE}.\n",
       "\\item[\\code{iso}]  an optional boolean that can be used to force a tensor-product covariance structure (see \\code{\\LinkA{covTensorProduct-class}{covTensorProduct.Rdash.class}}) to have a range parameter common to all dimensions. Default is \\code{FALSE}. Not used (at this stage) for the power-exponential type.\n",
       "\\item[\\code{scaling}]  an optional boolean indicating whether a scaling on the covariance structure should be used.\n",
       "\\item[\\code{knots}]  an optional list of knots for scaling. The j-th element is a vector containing the knots for dimension j. If \\code{scaling=TRUE} and knots are not specified, than knots are fixed to 0 and 1 in each dimension (which corresponds to affine scaling for the domain [0,1]\\textasciicircum{}d).\n",
       "\\item[\\code{kernel}]  an optional function containing a new covariance structure. At this stage, the parameters must be provided as well, and are not estimated. See an example below.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The optimisers are tunable by the user by the argument \\code{control}. \n",
       "Most of the control parameters proposed by \\code{BFGS} and \\code{genoud} can be passed to \\code{control} except the ones that must be forced [for the purpose of optimization setting], as indicated in the table below. See \\code{\\LinkA{optim}{optim}} and  \\code{\\LinkA{genoud}{genoud}} to get more details about them.\n",
       "\n",
       "\n",
       "\\Tabular{ll}{\n",
       "BFGS & \\code{trace}, \\code{parscale}, \\code{ndeps}, \\code{maxit}, \\code{abstol}, \\code{reltol}, \\code{REPORT}, \\code{lnm}, \\code{factr}, \\code{pgtol} \\\\{}\n",
       "genoud & all parameters EXCEPT: \\code{fn, nvars, max, starting.values, Domains, gr, gradient.check, boundary.enforcement, hessian} and \\code{optim.method}. \\\\{} \n",
       "}\n",
       "\n",
       "Notice that the right places to specify the optional starting values and boundaries are in \\code{parinit} and \\code{lower, upper}, as explained above. Some additional possibilities and initial values are indicated in the table below:\n",
       "\n",
       "\n",
       "\\Tabular{ll}{\n",
       "\\code{trace} & Turn it to \\code{FALSE} to avoid printing during optimization progress.\\\\{}\n",
       "\n",
       "\\code{pop.size} & For method \\code{\"BFGS\"}, it is the number of candidate initial points generated before optimization starts (see \\code{parinit} above). Default is 20. For method \\code{\"gen\"}, \\code{\"pop.size\"} is the population size, set by default at min(20, 4+3*log(nb of variables) \\\\{}\n",
       "\\code{max.generations} & Default is 5 \\\\{}\n",
       "\\code{wait.generations} & Default is 2 \\\\{}\n",
       "\\code{BFGSburnin} & Default is 0 \\\\{}\n",
       "}\n",
       "\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "An object of class \\code{km} (see \\code{\\LinkA{km-class}{km.Rdash.class}}).\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       " O. Roustant, D. Ginsbourger, Ecole des Mines de St-Etienne. \n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       " \n",
       "\n",
       "N.A.C. Cressie (1993), \\emph{Statistics for spatial data}, Wiley series in probability and mathematical statistics.\n",
       "\n",
       "D. Ginsbourger (2009), \\emph{Multiples metamodeles pour l'approximation et l'optimisation\n",
       "de fonctions numeriques multivariables}, Ph.D. thesis, Ecole Nationale Superieure des\n",
       "Mines de Saint-Etienne, 2009.\n",
       "\n",
       "D. Ginsbourger, D. Dupuy, A. Badea, O. Roustant, and L. Carraro (2009), A note on the choice and the estimation of kriging models for the analysis of deterministic computer experiments, \\emph{Applied Stochastic Models for Business and Industry}, \\bold{25} no. 2, 115-131.\n",
       "\n",
       "A.G. Journel and M.E. Rossi (1989), When do we need a trend model in kriging ?, \\emph{Mathematical Geology}, \\bold{21} no. 7, 715-739.\n",
       "\n",
       "D.G. Krige (1951), A statistical approach to some basic mine valuation problems on the witwatersrand, \\emph{J. of the Chem., Metal. and Mining Soc. of South Africa}, \\bold{52} no. 6, 119-139.\n",
       "\n",
       "R. Li and A. Sudjianto (2005), Analysis of Computer Experiments Using Penalized Likelihood in Gaussian Kriging Models, \\emph{Technometrics}, \\bold{47} no. 2, 111-120.\n",
       "\n",
       "K.V. Mardia and R.J. Marshall (1984), Maximum likelihood estimation of models for residual covariance in spatial regression, \\emph{Biometrika}, \\bold{71}, 135-146.\n",
       "\n",
       "J.D. Martin and T.W. Simpson (2005), Use of kriging models to approximate deterministic computer models, \\emph{AIAA Journal}, \\bold{43} no. 4, 853-863.\n",
       "\n",
       "G. Matheron (1969), Le krigeage universel, \\emph{Les Cahiers du Centre de Morphologie Mathematique de Fontainebleau}, \\bold{1}.\n",
       "\n",
       "W.R. Jr. Mebane and J.S. Sekhon, in press (2009), Genetic optimization using derivatives: The rgenoud package for R, \\emph{Journal of Statistical Software}.\n",
       "\n",
       "J.-S. Park and J. Baek (2001), Efficient computation of maximum likelihood estimators in a spatial linear model with power exponential covariogram, \\emph{Computer Geosciences}, \\bold{27} no. 1, 1-7.\n",
       "\n",
       "C.E. Rasmussen and C.K.I. Williams (2006), \\emph{Gaussian Processes for Machine Learning}, the MIT Press, \\url{http://www.GaussianProcess.org/gpml}\n",
       "\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       " \\code{\\LinkA{kmData}{kmData}} for another interface with the data,\n",
       "\\code{\\LinkA{show,km-method}{show,km.Rdash.method}},\n",
       "\\code{\\LinkA{predict,km-method}{predict,km.Rdash.method}},\n",
       "\\code{\\LinkA{plot,km-method}{plot,km.Rdash.method}}.\n",
       "Some programming details and initialization choices can be found in \\code{\\LinkA{kmEstimate}{kmEstimate}}, \\code{\\LinkA{kmNoNugget.init}{kmNoNugget.init}},\n",
       "\\code{\\LinkA{km1Nugget.init}{km1Nugget.init}} and \\code{\\LinkA{kmNuggets.init}{kmNuggets.init}} \n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "# ----------------------------------\n",
       "# A 2D example - Branin-Hoo function\n",
       "# ----------------------------------\n",
       "\n",
       "# a 16-points factorial design, and the corresponding response\n",
       "d <- 2; n <- 16\n",
       "design.fact <- expand.grid(x1=seq(0,1,length=4), x2=seq(0,1,length=4))\n",
       "y <- apply(design.fact, 1, branin) \n",
       "\n",
       "# kriging model 1 : matern5_2 covariance structure, no trend, no nugget effect\n",
       "m1 <- km(design=design.fact, response=y)\n",
       "\n",
       "# kriging model 2 : matern5_2 covariance structure, \n",
       "#                   linear trend + interactions, no nugget effect\n",
       "m2 <- km(~.^2, design=design.fact, response=y)\n",
       "\n",
       "# graphics \n",
       "n.grid <- 50\n",
       "x.grid <- y.grid <- seq(0,1,length=n.grid)\n",
       "design.grid <- expand.grid(x1=x.grid, x2=y.grid)\n",
       "response.grid <- apply(design.grid, 1, branin)\n",
       "predicted.values.model1 <- predict(m1, design.grid, \"UK\")$mean\n",
       "predicted.values.model2 <- predict(m2, design.grid, \"UK\")$mean\n",
       "par(mfrow=c(3,1))\n",
       "contour(x.grid, y.grid, matrix(response.grid, n.grid, n.grid), 50, main=\"Branin\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "contour(x.grid, y.grid, matrix(predicted.values.model1, n.grid, n.grid), 50, \n",
       "        main=\"Ordinary Kriging\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "contour(x.grid, y.grid, matrix(predicted.values.model2, n.grid, n.grid), 50, \n",
       "        main=\"Universal Kriging\")\n",
       "points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "par(mfrow=c(1,1))\n",
       "\n",
       "\n",
       "# (same example) how to use the multistart argument\n",
       "# -------------------------------------------------\n",
       "require(foreach)\n",
       "\n",
       "# below an example for a computer with 2 cores, but also work with 1 core\n",
       "\n",
       "nCores <- 2\n",
       "require(doParallel)\n",
       "cl <-  makeCluster(nCores) \n",
       "registerDoParallel(cl)\n",
       "\n",
       "# kriging model 1, with 4 starting points\n",
       "m1_4 <- km(design=design.fact, response=y, multistart=4)\n",
       "\n",
       "stopCluster(cl)\n",
       "\n",
       "# -------------------------------\n",
       "# A 1D example with penalized MLE\n",
       "# -------------------------------\n",
       "\n",
       "# from Fang K.-T., Li R. and Sudjianto A. (2006), \"Design and Modeling for \n",
       "# Computer Experiments\", Chapman & Hall, pages 145-152\n",
       "\n",
       "n <- 6; d <- 1\n",
       "x <- seq(from=0, to=10, length=n)\n",
       "y <- sin(x)\n",
       "t <- seq(0,10, length=100)\n",
       "\n",
       "# one should add a small nugget effect, to avoid numerical problems\n",
       "epsilon <- 1e-3\n",
       "model <- km(formula<- ~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"gauss\", penalty=list(fun=\"SCAD\", value=3), nugget=epsilon)\n",
       "\n",
       "p <- predict(model, data.frame(x=t), \"UK\")\n",
       "\n",
       "plot(t, p$mean, type=\"l\", xlab=\"x\", ylab=\"y\", \n",
       "                     main=\"Prediction via Penalized Kriging\")\n",
       "points(x, y, col=\"red\", pch=19)\n",
       "lines(t, sin(t), lty=2, col=\"blue\")\n",
       "legend(0, -0.5, legend=c(\"Sine Curve\", \"Sample\", \"Fitted Curve\"), \n",
       "       pch=c(-1,19,-1), lty=c(2,-1,1), col=c(\"blue\",\"red\",\"black\"))\n",
       "\n",
       "\n",
       "# ------------------------------------------------------------------------\n",
       "# A 1D example with known trend and known or unknown covariance parameters\n",
       "# ------------------------------------------------------------------------\n",
       "\n",
       "x <- c(0, 0.4, 0.6, 0.8, 1);\n",
       "y <- c(-0.3, 0, -0.8, 0.5, 0.9)\n",
       "\n",
       "theta <- 0.01; sigma <- 3; trend <- c(-1,2)\n",
       "\n",
       "model <- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"matern5_2\", coef.trend=trend, coef.cov=theta, \n",
       "            coef.var=sigma^2)\n",
       "\n",
       "# below: if you want to specify trend only, and estimate both theta and sigma:\n",
       "# model <- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "#             covtype=\"matern5_2\", coef.trend=trend, lower=0.2)\n",
       "# Remark: a lower bound or penalty function is useful here,\n",
       "#         due to the very small number of design points...\n",
       "\n",
       "# kriging with gaussian covariance C(x,y)=sigma^2 * exp(-[(x-y)/theta]^2), \n",
       "#         and linear trend t(x) = -1 + 2x\n",
       "\n",
       "t <- seq(from=0, to=1, by=0.005)\n",
       "p <- predict(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "# beware that type = \"SK\" for known parameters (default is \"UK\")\n",
       "\n",
       "plot(t, p$mean, type=\"l\", ylim=c(-7,7), xlab=\"x\", ylab=\"y\")\n",
       "lines(t, p$lower95, col=\"black\", lty=2)\n",
       "lines(t, p$upper95, col=\"black\", lty=2)\n",
       "points(x, y, col=\"red\", pch=19)\n",
       "abline(h=0)\n",
       "\n",
       "\n",
       "# --------------------------------------------------------------\n",
       "# Kriging with noisy observations (heterogeneous noise variance)\n",
       "# --------------------------------------------------------------\n",
       "\n",
       "fundet <- function(x){\n",
       "return((sin(10*x)/(1+x)+2*cos(5*x)*x^3+0.841)/1.6)\n",
       "}\n",
       "\n",
       "level <- 0.5; epsilon <- 0.1\n",
       "theta <- 1/sqrt(30); p <- 2; n <- 10\n",
       "x <- seq(0,1, length=n)\n",
       "\n",
       "# Heteregeneous noise variances: number of Monte Carlo evaluation among \n",
       "#                                a total budget of 1000 stochastic simulations\n",
       "MC_numbers <- c(10,50,50,290,25,75,300,10,40,150)\n",
       "noise.var <- 3/MC_numbers\n",
       "\n",
       "# Making noisy observations from 'fundet' function (defined above)\n",
       "y <- fundet(x) + noise.var*rnorm(length(x))\n",
       "\n",
       "# kriging model definition (no estimation here)\n",
       "model <- km(y~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "            covtype=\"gauss\", coef.trend=0, coef.cov=theta, coef.var=1, \n",
       "            noise.var=noise.var)\n",
       "\n",
       "# prediction\n",
       "t <- seq(0, 1, by=0.01)\n",
       "p <- predict.km(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "lower <- p$lower95; upper <- p$upper95\n",
       "\n",
       "# graphics\n",
       "par(mfrow=c(1,1))\n",
       "plot(t, p$mean, type=\"l\", ylim=c(1.1*min(c(lower,y)) , 1.1*max(c(upper,y))), \n",
       "                xlab=\"x\", ylab=\"y\",col=\"blue\", lwd=1.5)\n",
       "polygon(c(t,rev(t)), c(lower, rev(upper)), col=gray(0.9), border = gray(0.9))\n",
       "lines(t, p$mean, type=\"l\", ylim=c(min(lower) ,max(upper)), xlab=\"x\", ylab=\"y\",\n",
       "                 col=\"blue\", lwd=1)\n",
       "lines(t, lower, col=\"blue\", lty=4, lwd=1.7)\n",
       "lines(t, upper, col=\"blue\", lty=4, lwd=1.7)\n",
       "lines(t, fundet(t), col=\"black\", lwd=2)\n",
       "points(x, y, pch=8,col=\"blue\")\n",
       "text(x, y, labels=MC_numbers, pos=3)\n",
       "\n",
       "\n",
       "# -----------------------------\n",
       "# Checking parameter estimation \n",
       "# -----------------------------\n",
       "\n",
       "d <- 3       \t# problem dimension\n",
       "n <- 40\t\t\t# size of the experimental design\n",
       "design <- matrix(runif(n*d), n, d)\n",
       "\n",
       "covtype <- \"matern5_2\"\t\t\n",
       "theta <- c(0.3, 0.5, 1)\t\t# the parameters to be found by estimation\n",
       "sigma <- 2\n",
       "nugget <- NULL  # choose a numeric value if you want to estimate nugget \n",
       "nugget.estim <- FALSE # choose TRUE if you want to estimate it\n",
       "\n",
       "n.simu <- 30\t\t# number of simulations\n",
       "sigma2.estimate <- nugget.estimate <- mu.estimate <- matrix(0, n.simu, 1)\n",
       "coef.estimate <- matrix(0, n.simu, length(theta))\n",
       "\n",
       "model <- km(~1, design=data.frame(design), response=rep(0,n), covtype=covtype, \n",
       "            coef.trend=0, coef.cov=theta, coef.var=sigma^2, nugget=nugget)\n",
       "y <- simulate(model, nsim=n.simu)\n",
       "\n",
       "for (i in 1:n.simu) {\n",
       "\t# parameter estimation: tune the optimizer by changing optim.method, control\n",
       "\tmodel.estimate <- km(~1, design=data.frame(design), response=data.frame(y=y[i,]), \n",
       "\tcovtype=covtype, optim.method=\"BFGS\", control=list(pop.size=50, trace=FALSE), \n",
       "        nugget.estim=nugget.estim) \n",
       "\t\n",
       "\t# store results\n",
       "\tcoef.estimate[i,] <- covparam2vect(model.estimate@covariance)\n",
       "\tsigma2.estimate[i] <- model.estimate@covariance@sd2\n",
       "\tmu.estimate[i] <- model.estimate@trend.coef\n",
       "\tif (nugget.estim) nugget.estimate[i] <- model.estimate@covariance@nugget\n",
       "}\n",
       "\n",
       "# comparison true values / estimation\n",
       "cat(\"\\nResults with \", n, \"design points, \n",
       "    obtained with \", n.simu, \"simulations\\n\\n\",\n",
       "    \"Median of covar. coef. estimates: \", apply(coef.estimate, 2, median), \"\\n\",\n",
       "    \"Median of trend  coef. estimates: \", median(mu.estimate), \"\\n\", \n",
       "    \"Mean of the var. coef. estimates: \", mean(sigma2.estimate))\n",
       "if (nugget.estim) cat(\"\\nMean of the nugget effect estimates: \", \n",
       "                      mean(nugget.estimate))\n",
       "\n",
       "# one figure for this specific example - to be adapted\n",
       "split.screen(c(2,1))        # split display into two screens\n",
       "split.screen(c(1,2), screen = 2) # now split the bottom half into 3\n",
       "\n",
       "screen(1)\n",
       "boxplot(coef.estimate[,1], coef.estimate[,2], coef.estimate[,3], \n",
       "        names=c(\"theta1\", \"theta2\", \"theta3\"))\n",
       "abline(h=theta, col=\"red\")\n",
       "fig.title <- paste(\"Empirical law of the parameter estimates \n",
       "                    (n=\", n , \", n.simu=\", n.simu, \")\", sep=\"\")\n",
       "title(fig.title)\n",
       "\n",
       "screen(3)\n",
       "boxplot(mu.estimate, xlab=\"mu\")\n",
       "abline(h=0, col=\"red\")\n",
       "\n",
       "screen(4)\n",
       "boxplot(sigma2.estimate, xlab=\"sigma2\")\n",
       "abline(h=sigma^2, col=\"red\")\n",
       "\n",
       "close.screen(all = TRUE)  \n",
       "\n",
       "# ----------------------------------------------------------\n",
       "# Kriging with non-linear scaling on Xiong et al.'s function\n",
       "# ----------------------------------------------------------\n",
       "\n",
       "f11_xiong <- function(x){ \n",
       "return( sin(30*(x - 0.9)^4)*cos(2*(x - 0.9)) + (x - 0.9)/2)\n",
       "}\n",
       "\n",
       "t <- seq(0,1,,300)\n",
       "f <- f11_xiong(t)\n",
       "\n",
       "plot(t,f,type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "\n",
       "doe <- data.frame(x=seq(0,1,,20))\n",
       "resp <- f11_xiong(doe)\n",
       "\n",
       "knots <- list(  c(0,0.5,1) ) \n",
       "eta <- list(c(15, 2, 0.5))\n",
       "m <- km(design=doe, response=resp, scaling=TRUE, gr=TRUE, \n",
       "knots=knots, covtype=\"matern5_2\",  coef.var=1, coef.trend=0)\n",
       "\n",
       "p <- predict(m, data.frame(x=t), \"UK\")\n",
       "\n",
       "plot(t, f, type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "\n",
       "lines(t, p$mean, col=\"blue\", lty=2, lwd=2)\n",
       "lines(t, p$mean + 2*p$sd, col=\"blue\")\n",
       "lines(t, p$mean - 2*p$sd,col=\"blue\")\n",
       "\n",
       "abline(v=knots[[1]], lty=2, col=\"green\")\n",
       "\n",
       "\n",
       "# -----------------------------------------------------\n",
       "# Kriging with a symmetric kernel: example with covUser\n",
       "# -----------------------------------------------------\n",
       "\n",
       "x <- c(0, 0.15, 0.3, 0.4, 0.5)\n",
       "y <- c(0.3, -0.2, 0, 0.5, 0.2)\n",
       "\n",
       "k <- function(x,y) {\n",
       "  theta <- 0.15\n",
       "  0.5*exp(-((x-y)/theta)^2) + 0.5*exp(-((1-x-y)/theta)^2)    \n",
       "}\n",
       "\n",
       "muser <- km(design=data.frame(x=x), response=data.frame(y=y), \n",
       "            coef.trend=0, kernel=k)\n",
       "\n",
       "u <- seq(from=0, to=1, by=0.01)\n",
       "puser <- predict(muser, newdata=data.frame(x=u), type=\"SK\")\n",
       "\n",
       "set.seed(0)\n",
       "nsim <- 5\n",
       "zuser <- simulate(muser, nsim=nsim, newdata=data.frame(x=u), cond=TRUE, nugget.sim=1e-8)\n",
       "par(mfrow=c(1,1))\n",
       "matplot(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "polygon(c(u, rev(u)), c(puser$upper, rev(puser$lower)), col=\"lightgrey\", border=NA)\n",
       "lines(u, puser$mean, lwd=5, col=\"blue\", lty=\"dotted\")\n",
       "matlines(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "points(x, y, pch=19, cex=1.5)\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "km                 package:DiceKriging                 R Documentation\n",
       "\n",
       "_\bF_\bi_\bt _\ba_\bn_\bd/_\bo_\br _\bc_\br_\be_\ba_\bt_\be _\bk_\br_\bi_\bg_\bi_\bn_\bg _\bm_\bo_\bd_\be_\bl_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘km’ is used to fit kriging models when parameters are unknown, or\n",
       "     to create ‘km’ objects otherwise. In both cases, the result is a\n",
       "     ‘km’ object. If parameters are unknown, they are estimated by\n",
       "     Maximum Likelihood. As a beta version, Penalized Maximum\n",
       "     Likelihood Estimation is also possible if some penalty is given,\n",
       "     or Leave-One-Out for noise-free observations.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     km(formula=~1, design, response, covtype=\"matern5_2\",\n",
       "        coef.trend = NULL, coef.cov = NULL, coef.var = NULL,\n",
       "        nugget = NULL, nugget.estim=FALSE, noise.var=NULL, estim.method=\"MLE\",\n",
       "        penalty = NULL, optim.method = \"BFGS\", lower = NULL, upper = NULL, \n",
       "        parinit = NULL, multistart = 1, control = NULL, gr = TRUE, \n",
       "        iso=FALSE, scaling=FALSE, knots=NULL, kernel=NULL)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       " formula: an optional object of class \"formula\" specifying the linear\n",
       "          trend of the kriging model (see ‘lm’). This formula should\n",
       "          concern only the input variables, and not the output\n",
       "          (response). If there is any, it is automatically dropped. In\n",
       "          particular, no response transformation is available yet. The\n",
       "          default is ‘~1’, which defines a constant trend.\n",
       "\n",
       "  design: a data frame representing the design of experiments. The ith\n",
       "          row contains the values of the d input variables\n",
       "          corresponding to the ith evaluation\n",
       "\n",
       "response: a vector (or 1-column matrix or data frame) containing the\n",
       "          values of the 1-dimensional output given by the objective\n",
       "          function at the ‘design’ points.\n",
       "\n",
       " covtype: an optional character string specifying the covariance\n",
       "          structure to be used, to be chosen between ‘\"gauss\"’,\n",
       "          ‘\"matern5_2\"’, ‘\"matern3_2\"’, ‘\"exp\"’ or ‘\"powexp\"’. See a\n",
       "          full description of available covariance kernels in\n",
       "          ‘covTensorProduct-class’. Default is ‘\"matern5_2\"’. See also\n",
       "          the argument ‘kernel’ that allows the user to build its own\n",
       "          covariance structure.\n",
       "\n",
       "coef.trend,: (see below)\n",
       "\n",
       "coef.cov,: (see below)\n",
       "\n",
       "coef.var: optional vectors containing the values for the trend,\n",
       "          covariance and variance parameters. For estimation, 4 cases\n",
       "          are implemented: 1. (All unknown) If all are missing, all are\n",
       "          estimated. 2. (All known) If all are provided, no estimation\n",
       "          is performed; 3. (Known trend) If ‘coef.trend’ is provided\n",
       "          but at least one of ‘coef.cov’ or ‘coef.var’ is missing, then\n",
       "          BOTH ‘coef.cov’ and ‘coef.var’ are estimated; 4. (Unknown\n",
       "          trend) If ‘coef.cov’ and ‘coef.var’ are provided but\n",
       "          ‘coef.trend’ is missing, then ‘coef.trend’ is estimated (GLS\n",
       "          formula).\n",
       "\n",
       "  nugget: an optional variance value standing for the homogeneous\n",
       "          nugget effect.\n",
       "\n",
       "nugget.estim: an optional boolean indicating whether the nugget effect\n",
       "          should be estimated. Note that this option does not concern\n",
       "          the case of heterogeneous noisy observations (see ‘noise.var’\n",
       "          below). If ‘nugget’ is given, it is used as an initial value.\n",
       "          Default is ‘FALSE’.\n",
       "\n",
       "noise.var: for noisy observations : an optional vector containing the\n",
       "          noise variance at each observation. This is useful for\n",
       "          stochastic simulators. Default is ‘NULL’.\n",
       "\n",
       "estim.method: a character string specifying the method by which unknown\n",
       "          parameters are estimated. Default is ‘\"MLE\"’ (Maximum\n",
       "          Likelihood). At this stage, a beta version of leave-One-Out\n",
       "          estimation (‘estim.method=\"LOO\"’) is also implemented for\n",
       "          noise-free observations.\n",
       "\n",
       " penalty: (beta version) an optional list suitable for Penalized\n",
       "          Maximum Likelihood Estimation. The list must contain the item\n",
       "          ‘fun’ indicating the penalty function, and the item ‘value’\n",
       "          equal to the value of the penalty parameter. At this stage\n",
       "          the only available ‘fun’ is ‘\"SCAD\"’, and ‘covtype’ must be\n",
       "          ‘\"gauss\"’. Default is ‘NULL’, corresponding to (un-penalized)\n",
       "          Maximum Likelihood Estimation.\n",
       "\n",
       "optim.method: an optional character string indicating which\n",
       "          optimization method is chosen for the likelihood\n",
       "          maximization. ‘\"BFGS\"’ is the ‘optim’ quasi-Newton procedure\n",
       "          of package ‘stats’, with the method \"L-BFGS-B\". ‘\"gen\"’ is\n",
       "          the ‘genoud’ genetic algorithm (using derivatives) from\n",
       "          package ‘rgenoud’ (>= 5.3.3).\n",
       "\n",
       " lower, : (see below)\n",
       "\n",
       "   upper: optional vectors containing the bounds of the correlation\n",
       "          parameters for optimization. The default values are given by\n",
       "          ‘covParametersBounds’.\n",
       "\n",
       " parinit: an optional vector containing the initial values for the\n",
       "          variables to be optimized over. If no vector is given, an\n",
       "          initial point is generated as follows. For method ‘\"gen\"’,\n",
       "          the initial point is generated uniformly inside the\n",
       "          hyper-rectangle domain defined by ‘lower’ and ‘upper’. For\n",
       "          method ‘\"BFGS\"’, some points (see ‘control’ below) are\n",
       "          generated uniformly in the domain. Then the best point with\n",
       "          respect to the likelihood (or penalized likelihood, see\n",
       "          ‘penalty’) criterion is chosen.\n",
       "\n",
       "multistart: an optional integer indicating the number of initial points\n",
       "          from which running the BFGS optimizer. These points will be\n",
       "          selected as the best ‘multistart’ one(s) among those\n",
       "          evaluated (see above ‘parinit’). The multiple optimizations\n",
       "          will be performed in parallel provided that a parallel\n",
       "          backend is registered (see package ‘foreach’).\n",
       "\n",
       " control: an optional list of control parameters for optimization. See\n",
       "          details below.\n",
       "\n",
       "      gr: an optional boolean indicating whether the analytical\n",
       "          gradient should be used. Default is ‘TRUE’.\n",
       "\n",
       "     iso: an optional boolean that can be used to force a\n",
       "          tensor-product covariance structure (see\n",
       "          ‘covTensorProduct-class’) to have a range parameter common to\n",
       "          all dimensions. Default is ‘FALSE’. Not used (at this stage)\n",
       "          for the power-exponential type.\n",
       "\n",
       " scaling: an optional boolean indicating whether a scaling on the\n",
       "          covariance structure should be used.\n",
       "\n",
       "   knots: an optional list of knots for scaling. The j-th element is a\n",
       "          vector containing the knots for dimension j. If\n",
       "          ‘scaling=TRUE’ and knots are not specified, than knots are\n",
       "          fixed to 0 and 1 in each dimension (which corresponds to\n",
       "          affine scaling for the domain [0,1]^d).\n",
       "\n",
       "  kernel: an optional function containing a new covariance structure.\n",
       "          At this stage, the parameters must be provided as well, and\n",
       "          are not estimated. See an example below.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The optimisers are tunable by the user by the argument ‘control’.\n",
       "     Most of the control parameters proposed by ‘BFGS’ and ‘genoud’ can\n",
       "     be passed to ‘control’ except the ones that must be forced [for\n",
       "     the purpose of optimization setting], as indicated in the table\n",
       "     below. See ‘optim’ and ‘genoud’ to get more details about them.\n",
       "\n",
       "       BFGS    ‘trace’, ‘parscale’, ‘ndeps’, ‘maxit’, ‘abstol’, ‘reltol’, ‘REPORT’, ‘lnm’, ‘factr’, ‘pgtol’                                             \n",
       "       genoud  all parameters EXCEPT: ‘fn, nvars, max, starting.values, Domains, gr, gradient.check, boundary.enforcement, hessian’ and ‘optim.method’. \n",
       "      \n",
       "     Notice that the right places to specify the optional starting\n",
       "     values and boundaries are in ‘parinit’ and ‘lower, upper’, as\n",
       "     explained above. Some additional possibilities and initial values\n",
       "     are indicated in the table below:\n",
       "\n",
       "       ‘trace’             Turn it to ‘FALSE’ to avoid printing during optimization progress.                                                                                                                                                                                       \n",
       "       ‘pop.size’          For method ‘\"BFGS\"’, it is the number of candidate initial points generated before optimization starts (see ‘parinit’ above). Default is 20. For method ‘\"gen\"’, ‘\"pop.size\"’ is the population size, set by default at min(20, 4+3*log(nb of variables) \n",
       "       ‘max.generations’   Default is 5                                                                                                                                                                                                                                             \n",
       "       ‘wait.generations’  Default is 2                                                                                                                                                                                                                                             \n",
       "       ‘BFGSburnin’        Default is 0                                                                                                                                                                                                                                             \n",
       "      \n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     An object of class ‘km’ (see ‘km-class’).\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     O. Roustant, D. Ginsbourger, Ecole des Mines de St-Etienne.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     N.A.C. Cressie (1993), _Statistics for spatial data_, Wiley series\n",
       "     in probability and mathematical statistics.\n",
       "\n",
       "     D. Ginsbourger (2009), _Multiples metamodeles pour l'approximation\n",
       "     et l'optimisation de fonctions numeriques multivariables_, Ph.D.\n",
       "     thesis, Ecole Nationale Superieure des Mines de Saint-Etienne,\n",
       "     2009.\n",
       "\n",
       "     D. Ginsbourger, D. Dupuy, A. Badea, O. Roustant, and L. Carraro\n",
       "     (2009), A note on the choice and the estimation of kriging models\n",
       "     for the analysis of deterministic computer experiments, _Applied\n",
       "     Stochastic Models for Business and Industry_, *25* no. 2, 115-131.\n",
       "\n",
       "     A.G. Journel and M.E. Rossi (1989), When do we need a trend model\n",
       "     in kriging ?, _Mathematical Geology_, *21* no. 7, 715-739.\n",
       "\n",
       "     D.G. Krige (1951), A statistical approach to some basic mine\n",
       "     valuation problems on the witwatersrand, _J. of the Chem., Metal.\n",
       "     and Mining Soc. of South Africa_, *52* no. 6, 119-139.\n",
       "\n",
       "     R. Li and A. Sudjianto (2005), Analysis of Computer Experiments\n",
       "     Using Penalized Likelihood in Gaussian Kriging Models,\n",
       "     _Technometrics_, *47* no. 2, 111-120.\n",
       "\n",
       "     K.V. Mardia and R.J. Marshall (1984), Maximum likelihood\n",
       "     estimation of models for residual covariance in spatial\n",
       "     regression, _Biometrika_, *71*, 135-146.\n",
       "\n",
       "     J.D. Martin and T.W. Simpson (2005), Use of kriging models to\n",
       "     approximate deterministic computer models, _AIAA Journal_, *43*\n",
       "     no. 4, 853-863.\n",
       "\n",
       "     G. Matheron (1969), Le krigeage universel, _Les Cahiers du Centre\n",
       "     de Morphologie Mathematique de Fontainebleau_, *1*.\n",
       "\n",
       "     W.R. Jr. Mebane and J.S. Sekhon, in press (2009), Genetic\n",
       "     optimization using derivatives: The rgenoud package for R,\n",
       "     _Journal of Statistical Software_.\n",
       "\n",
       "     J.-S. Park and J. Baek (2001), Efficient computation of maximum\n",
       "     likelihood estimators in a spatial linear model with power\n",
       "     exponential covariogram, _Computer Geosciences_, *27* no. 1, 1-7.\n",
       "\n",
       "     C.E. Rasmussen and C.K.I. Williams (2006), _Gaussian Processes for\n",
       "     Machine Learning_, the MIT Press, <URL:\n",
       "     http://www.GaussianProcess.org/gpml>\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘kmData’ for another interface with the data, ‘show,km-method’,\n",
       "     ‘predict,km-method’, ‘plot,km-method’.  Some programming details\n",
       "     and initialization choices can be found in ‘kmEstimate’,\n",
       "     ‘kmNoNugget.init’, ‘km1Nugget.init’ and ‘kmNuggets.init’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # ----------------------------------\n",
       "     # A 2D example - Branin-Hoo function\n",
       "     # ----------------------------------\n",
       "     \n",
       "     # a 16-points factorial design, and the corresponding response\n",
       "     d <- 2; n <- 16\n",
       "     design.fact <- expand.grid(x1=seq(0,1,length=4), x2=seq(0,1,length=4))\n",
       "     y <- apply(design.fact, 1, branin) \n",
       "     \n",
       "     # kriging model 1 : matern5_2 covariance structure, no trend, no nugget effect\n",
       "     m1 <- km(design=design.fact, response=y)\n",
       "     \n",
       "     # kriging model 2 : matern5_2 covariance structure, \n",
       "     #                   linear trend + interactions, no nugget effect\n",
       "     m2 <- km(~.^2, design=design.fact, response=y)\n",
       "     \n",
       "     # graphics \n",
       "     n.grid <- 50\n",
       "     x.grid <- y.grid <- seq(0,1,length=n.grid)\n",
       "     design.grid <- expand.grid(x1=x.grid, x2=y.grid)\n",
       "     response.grid <- apply(design.grid, 1, branin)\n",
       "     predicted.values.model1 <- predict(m1, design.grid, \"UK\")$mean\n",
       "     predicted.values.model2 <- predict(m2, design.grid, \"UK\")$mean\n",
       "     par(mfrow=c(3,1))\n",
       "     contour(x.grid, y.grid, matrix(response.grid, n.grid, n.grid), 50, main=\"Branin\")\n",
       "     points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "     contour(x.grid, y.grid, matrix(predicted.values.model1, n.grid, n.grid), 50, \n",
       "             main=\"Ordinary Kriging\")\n",
       "     points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "     contour(x.grid, y.grid, matrix(predicted.values.model2, n.grid, n.grid), 50, \n",
       "             main=\"Universal Kriging\")\n",
       "     points(design.fact[,1], design.fact[,2], pch=17, cex=1.5, col=\"blue\")\n",
       "     par(mfrow=c(1,1))\n",
       "     \n",
       "     \n",
       "     # (same example) how to use the multistart argument\n",
       "     # -------------------------------------------------\n",
       "     require(foreach)\n",
       "     \n",
       "     # below an example for a computer with 2 cores, but also work with 1 core\n",
       "     \n",
       "     nCores <- 2\n",
       "     require(doParallel)\n",
       "     cl <-  makeCluster(nCores) \n",
       "     registerDoParallel(cl)\n",
       "     \n",
       "     # kriging model 1, with 4 starting points\n",
       "     m1_4 <- km(design=design.fact, response=y, multistart=4)\n",
       "     \n",
       "     stopCluster(cl)\n",
       "     \n",
       "     # -------------------------------\n",
       "     # A 1D example with penalized MLE\n",
       "     # -------------------------------\n",
       "     \n",
       "     # from Fang K.-T., Li R. and Sudjianto A. (2006), \"Design and Modeling for \n",
       "     # Computer Experiments\", Chapman & Hall, pages 145-152\n",
       "     \n",
       "     n <- 6; d <- 1\n",
       "     x <- seq(from=0, to=10, length=n)\n",
       "     y <- sin(x)\n",
       "     t <- seq(0,10, length=100)\n",
       "     \n",
       "     # one should add a small nugget effect, to avoid numerical problems\n",
       "     epsilon <- 1e-3\n",
       "     model <- km(formula<- ~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "                 covtype=\"gauss\", penalty=list(fun=\"SCAD\", value=3), nugget=epsilon)\n",
       "     \n",
       "     p <- predict(model, data.frame(x=t), \"UK\")\n",
       "     \n",
       "     plot(t, p$mean, type=\"l\", xlab=\"x\", ylab=\"y\", \n",
       "                          main=\"Prediction via Penalized Kriging\")\n",
       "     points(x, y, col=\"red\", pch=19)\n",
       "     lines(t, sin(t), lty=2, col=\"blue\")\n",
       "     legend(0, -0.5, legend=c(\"Sine Curve\", \"Sample\", \"Fitted Curve\"), \n",
       "            pch=c(-1,19,-1), lty=c(2,-1,1), col=c(\"blue\",\"red\",\"black\"))\n",
       "     \n",
       "     \n",
       "     # ------------------------------------------------------------------------\n",
       "     # A 1D example with known trend and known or unknown covariance parameters\n",
       "     # ------------------------------------------------------------------------\n",
       "     \n",
       "     x <- c(0, 0.4, 0.6, 0.8, 1);\n",
       "     y <- c(-0.3, 0, -0.8, 0.5, 0.9)\n",
       "     \n",
       "     theta <- 0.01; sigma <- 3; trend <- c(-1,2)\n",
       "     \n",
       "     model <- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "                 covtype=\"matern5_2\", coef.trend=trend, coef.cov=theta, \n",
       "                 coef.var=sigma^2)\n",
       "     \n",
       "     # below: if you want to specify trend only, and estimate both theta and sigma:\n",
       "     # model <- km(~x, design=data.frame(x=x), response=data.frame(y=y), \n",
       "     #             covtype=\"matern5_2\", coef.trend=trend, lower=0.2)\n",
       "     # Remark: a lower bound or penalty function is useful here,\n",
       "     #         due to the very small number of design points...\n",
       "     \n",
       "     # kriging with gaussian covariance C(x,y)=sigma^2 * exp(-[(x-y)/theta]^2), \n",
       "     #         and linear trend t(x) = -1 + 2x\n",
       "     \n",
       "     t <- seq(from=0, to=1, by=0.005)\n",
       "     p <- predict(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "     # beware that type = \"SK\" for known parameters (default is \"UK\")\n",
       "     \n",
       "     plot(t, p$mean, type=\"l\", ylim=c(-7,7), xlab=\"x\", ylab=\"y\")\n",
       "     lines(t, p$lower95, col=\"black\", lty=2)\n",
       "     lines(t, p$upper95, col=\"black\", lty=2)\n",
       "     points(x, y, col=\"red\", pch=19)\n",
       "     abline(h=0)\n",
       "     \n",
       "     \n",
       "     # --------------------------------------------------------------\n",
       "     # Kriging with noisy observations (heterogeneous noise variance)\n",
       "     # --------------------------------------------------------------\n",
       "     \n",
       "     fundet <- function(x){\n",
       "     return((sin(10*x)/(1+x)+2*cos(5*x)*x^3+0.841)/1.6)\n",
       "     }\n",
       "     \n",
       "     level <- 0.5; epsilon <- 0.1\n",
       "     theta <- 1/sqrt(30); p <- 2; n <- 10\n",
       "     x <- seq(0,1, length=n)\n",
       "     \n",
       "     # Heteregeneous noise variances: number of Monte Carlo evaluation among \n",
       "     #                                a total budget of 1000 stochastic simulations\n",
       "     MC_numbers <- c(10,50,50,290,25,75,300,10,40,150)\n",
       "     noise.var <- 3/MC_numbers\n",
       "     \n",
       "     # Making noisy observations from 'fundet' function (defined above)\n",
       "     y <- fundet(x) + noise.var*rnorm(length(x))\n",
       "     \n",
       "     # kriging model definition (no estimation here)\n",
       "     model <- km(y~1, design=data.frame(x=x), response=data.frame(y=y), \n",
       "                 covtype=\"gauss\", coef.trend=0, coef.cov=theta, coef.var=1, \n",
       "                 noise.var=noise.var)\n",
       "     \n",
       "     # prediction\n",
       "     t <- seq(0, 1, by=0.01)\n",
       "     p <- predict.km(model, newdata=data.frame(x=t), type=\"SK\")\n",
       "     lower <- p$lower95; upper <- p$upper95\n",
       "     \n",
       "     # graphics\n",
       "     par(mfrow=c(1,1))\n",
       "     plot(t, p$mean, type=\"l\", ylim=c(1.1*min(c(lower,y)) , 1.1*max(c(upper,y))), \n",
       "                     xlab=\"x\", ylab=\"y\",col=\"blue\", lwd=1.5)\n",
       "     polygon(c(t,rev(t)), c(lower, rev(upper)), col=gray(0.9), border = gray(0.9))\n",
       "     lines(t, p$mean, type=\"l\", ylim=c(min(lower) ,max(upper)), xlab=\"x\", ylab=\"y\",\n",
       "                      col=\"blue\", lwd=1)\n",
       "     lines(t, lower, col=\"blue\", lty=4, lwd=1.7)\n",
       "     lines(t, upper, col=\"blue\", lty=4, lwd=1.7)\n",
       "     lines(t, fundet(t), col=\"black\", lwd=2)\n",
       "     points(x, y, pch=8,col=\"blue\")\n",
       "     text(x, y, labels=MC_numbers, pos=3)\n",
       "     \n",
       "     \n",
       "     # -----------------------------\n",
       "     # Checking parameter estimation \n",
       "     # -----------------------------\n",
       "     \n",
       "     d <- 3          # problem dimension\n",
       "     n <- 40                 # size of the experimental design\n",
       "     design <- matrix(runif(n*d), n, d)\n",
       "     \n",
       "     covtype <- \"matern5_2\"          \n",
       "     theta <- c(0.3, 0.5, 1)         # the parameters to be found by estimation\n",
       "     sigma <- 2\n",
       "     nugget <- NULL  # choose a numeric value if you want to estimate nugget \n",
       "     nugget.estim <- FALSE # choose TRUE if you want to estimate it\n",
       "     \n",
       "     n.simu <- 30            # number of simulations\n",
       "     sigma2.estimate <- nugget.estimate <- mu.estimate <- matrix(0, n.simu, 1)\n",
       "     coef.estimate <- matrix(0, n.simu, length(theta))\n",
       "     \n",
       "     model <- km(~1, design=data.frame(design), response=rep(0,n), covtype=covtype, \n",
       "                 coef.trend=0, coef.cov=theta, coef.var=sigma^2, nugget=nugget)\n",
       "     y <- simulate(model, nsim=n.simu)\n",
       "     \n",
       "     for (i in 1:n.simu) {\n",
       "             # parameter estimation: tune the optimizer by changing optim.method, control\n",
       "             model.estimate <- km(~1, design=data.frame(design), response=data.frame(y=y[i,]), \n",
       "             covtype=covtype, optim.method=\"BFGS\", control=list(pop.size=50, trace=FALSE), \n",
       "             nugget.estim=nugget.estim) \n",
       "             \n",
       "             # store results\n",
       "             coef.estimate[i,] <- covparam2vect(model.estimate@covariance)\n",
       "             sigma2.estimate[i] <- model.estimate@covariance@sd2\n",
       "             mu.estimate[i] <- model.estimate@trend.coef\n",
       "             if (nugget.estim) nugget.estimate[i] <- model.estimate@covariance@nugget\n",
       "     }\n",
       "     \n",
       "     # comparison true values / estimation\n",
       "     cat(\"\\nResults with \", n, \"design points, \n",
       "         obtained with \", n.simu, \"simulations\\n\\n\",\n",
       "         \"Median of covar. coef. estimates: \", apply(coef.estimate, 2, median), \"\\n\",\n",
       "         \"Median of trend  coef. estimates: \", median(mu.estimate), \"\\n\", \n",
       "         \"Mean of the var. coef. estimates: \", mean(sigma2.estimate))\n",
       "     if (nugget.estim) cat(\"\\nMean of the nugget effect estimates: \", \n",
       "                           mean(nugget.estimate))\n",
       "     \n",
       "     # one figure for this specific example - to be adapted\n",
       "     split.screen(c(2,1))        # split display into two screens\n",
       "     split.screen(c(1,2), screen = 2) # now split the bottom half into 3\n",
       "     \n",
       "     screen(1)\n",
       "     boxplot(coef.estimate[,1], coef.estimate[,2], coef.estimate[,3], \n",
       "             names=c(\"theta1\", \"theta2\", \"theta3\"))\n",
       "     abline(h=theta, col=\"red\")\n",
       "     fig.title <- paste(\"Empirical law of the parameter estimates \n",
       "                         (n=\", n , \", n.simu=\", n.simu, \")\", sep=\"\")\n",
       "     title(fig.title)\n",
       "     \n",
       "     screen(3)\n",
       "     boxplot(mu.estimate, xlab=\"mu\")\n",
       "     abline(h=0, col=\"red\")\n",
       "     \n",
       "     screen(4)\n",
       "     boxplot(sigma2.estimate, xlab=\"sigma2\")\n",
       "     abline(h=sigma^2, col=\"red\")\n",
       "     \n",
       "     close.screen(all = TRUE)  \n",
       "     \n",
       "     # ----------------------------------------------------------\n",
       "     # Kriging with non-linear scaling on Xiong et al.'s function\n",
       "     # ----------------------------------------------------------\n",
       "     \n",
       "     f11_xiong <- function(x){ \n",
       "     return( sin(30*(x - 0.9)^4)*cos(2*(x - 0.9)) + (x - 0.9)/2)\n",
       "     }\n",
       "     \n",
       "     t <- seq(0,1,,300)\n",
       "     f <- f11_xiong(t)\n",
       "     \n",
       "     plot(t,f,type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "     \n",
       "     doe <- data.frame(x=seq(0,1,,20))\n",
       "     resp <- f11_xiong(doe)\n",
       "     \n",
       "     knots <- list(  c(0,0.5,1) ) \n",
       "     eta <- list(c(15, 2, 0.5))\n",
       "     m <- km(design=doe, response=resp, scaling=TRUE, gr=TRUE, \n",
       "     knots=knots, covtype=\"matern5_2\",  coef.var=1, coef.trend=0)\n",
       "     \n",
       "     p <- predict(m, data.frame(x=t), \"UK\")\n",
       "     \n",
       "     plot(t, f, type=\"l\", ylim=c(-1,0.6), lwd=2)\n",
       "     \n",
       "     lines(t, p$mean, col=\"blue\", lty=2, lwd=2)\n",
       "     lines(t, p$mean + 2*p$sd, col=\"blue\")\n",
       "     lines(t, p$mean - 2*p$sd,col=\"blue\")\n",
       "     \n",
       "     abline(v=knots[[1]], lty=2, col=\"green\")\n",
       "     \n",
       "     \n",
       "     # -----------------------------------------------------\n",
       "     # Kriging with a symmetric kernel: example with covUser\n",
       "     # -----------------------------------------------------\n",
       "     \n",
       "     x <- c(0, 0.15, 0.3, 0.4, 0.5)\n",
       "     y <- c(0.3, -0.2, 0, 0.5, 0.2)\n",
       "     \n",
       "     k <- function(x,y) {\n",
       "       theta <- 0.15\n",
       "       0.5*exp(-((x-y)/theta)^2) + 0.5*exp(-((1-x-y)/theta)^2)    \n",
       "     }\n",
       "     \n",
       "     muser <- km(design=data.frame(x=x), response=data.frame(y=y), \n",
       "                 coef.trend=0, kernel=k)\n",
       "     \n",
       "     u <- seq(from=0, to=1, by=0.01)\n",
       "     puser <- predict(muser, newdata=data.frame(x=u), type=\"SK\")\n",
       "     \n",
       "     set.seed(0)\n",
       "     nsim <- 5\n",
       "     zuser <- simulate(muser, nsim=nsim, newdata=data.frame(x=u), cond=TRUE, nugget.sim=1e-8)\n",
       "     par(mfrow=c(1,1))\n",
       "     matplot(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "     polygon(c(u, rev(u)), c(puser$upper, rev(puser$lower)), col=\"lightgrey\", border=NA)\n",
       "     lines(u, puser$mean, lwd=5, col=\"blue\", lty=\"dotted\")\n",
       "     matlines(u, t(zuser), type=\"l\", lty=rep(\"solid\", nsim), col=1:5, lwd=1)\n",
       "     points(x, y, pch=19, cex=1.5)\n",
       "     "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the function:\n",
    "#  km {DiceKriging}\n",
    "?km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compare different GP regression models\n",
    "\n",
    "Use the diagnostics we leant, and compare Gaussian process regression models deffering on the prior linear trend structure or the covariance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choose the 'Best' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the validity of the chossen 'Best' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Print the estimates of the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in show(myfun_km): object 'myfun_km' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in show(myfun_km): object 'myfun_km' not found\n"
     ]
    }
   ],
   "source": [
    "# PRINT THE PARAMETERS\n",
    "\n",
    "show(myfun_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot the posterior GPR mean and variance, as well as the real function (in contour plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
